{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your own concordance\n",
    "\n",
    "It took 500 Dominican munks to write the first concordance of the Latin bible, and it took Rabbi Mordecai Nathan 10 years to write the first concordance of the Hebrew bible. With Python, it only takes a matter of seconds to find words in a text, along with the surrounding words.\n",
    "\n",
    "Run each cell in this notebook one at a time, in order. If something in one cell doesn't work right, it might be because you have overwritten a variable, so try going back and running all the previous cells again.\n",
    "\n",
    "First run the code and check that everything works. Then, try modifying the code. Start with the first challenges, and then continue in order. Feel free to work together, and see how far you can get. The important thing is to learn, not to solve all the challenges!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.66.2)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: regex, joblib, nltk\n",
      "Successfully installed joblib-1.4.2 nltk-3.9.1 regex-2024.9.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install the natural language toolkit package (nltk), which has a copy of several texts, \n",
    "#including the King James Bible\n",
    "\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /home/ucloud/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the nltk package so that it is accessible to Python, and download a collection of texts from Project Gutenberg\n",
    "import nltk\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable called \"bible\" which contains the text of the King James bible.\n",
    "bible = nltk.corpus.gutenberg.raw('bible-kjv.txt')\n",
    "\n",
    "# make all characters lowercase\n",
    "bible = bible.lower()\n",
    "\n",
    "# remove the \"\\n\" characters, which indicate line breaks in the text (newlines)\n",
    "bible = bible.replace('\\n', ' ')\n",
    "\n",
    "# split up the text into a long list of individual words\n",
    "bible = bible.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a variable called \"concordance\", and fill it with every occurrence of the phrase \"this world\", and a few words preceeding and following \"this world\"\n",
    "concordance = []\n",
    "for i, val in enumerate(bible):\n",
    "    if val == \"world\":\n",
    "        if bible[i-1] == \"this\":\n",
    "            concordance.append(str(' '.join(bible[i-5:i+5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['for the children of this world are in their generation',\n",
       " 'them, the children of this world marry, and are given',\n",
       " 'hateth his life in this world shall keep it unto',\n",
       " 'shall the prince of this world be cast out. ',\n",
       " 'should depart out of this world unto the father, having',\n",
       " 'for the prince of this world cometh, and hath nothing',\n",
       " 'because the prince of this world is judged.  16:12',\n",
       " 'of the princes of this world knew: for had they',\n",
       " 'for the wisdom of this world is foolishness with god.',\n",
       " 'for the fashion of this world passeth away.  7:32',\n",
       " 'whom the god of this world hath blinded the minds',\n",
       " 'chosen the poor of this world rich in faith, and',\n",
       " 'saying, the kingdoms of this world are become the kingdoms']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at what the algorithm has found\n",
    "concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how many instances of the phrase \"this world\" were found\n",
    "len(concordance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try again, but this time let's just search for \"world\" by itself, not \"this world\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "concordance = []\n",
    "for i, val in enumerate(bible):\n",
    "    if val == \"world\":\n",
    "        concordance.append(str(' '.join(bible[i-5:i+5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and he hath set the world upon them.  2:9',\n",
       " 'appeared, the foundations of the world were discovered, at the',\n",
       " 'him, all the earth: the world also shall be stable,',\n",
       " 'upon the face of the world in the earth. ',\n",
       " 'and he shall judge the world in righteousness, he shall',\n",
       " 'and the foundations of the world were discovered at thy',\n",
       " 'all the ends of the world shall remember and turn',\n",
       " 'all the inhabitants of the world stand in awe of',\n",
       " 'not tell thee: for the world is mine, and the',\n",
       " 'is thine: as for the world and the fulness thereof,',\n",
       " 'he hath girded himself: the world also is stablished, that',\n",
       " 'that the lord reigneth: the world also shall be established',\n",
       " 'earth: he shall judge the world with righteousness, and the',\n",
       " 'also he hath set the world in their heart, so',\n",
       " 'and i will punish the world for their evil, and',\n",
       " 'kingdoms; 14:17 that made the world as a wilderness, and',\n",
       " 'fill the face of the world with cities.  14:22',\n",
       " 'all the kingdoms of the world upon the face of',\n",
       " 'mourneth and fadeth away, the world languisheth and fadeth away,',\n",
       " 'earth, the inhabitants of the world will learn righteousness. ',\n",
       " 'have the inhabitants of the world fallen.  26:19 thy',\n",
       " 'fill the face of the world with fruit.  27:7',\n",
       " 'not be ashamed nor confounded world without end.  45:18',\n",
       " 'since the beginning of the world men have not heard,',\n",
       " 'power, he hath established the world by his wisdom, and',\n",
       " 'power, he hath established the world by his wisdom, and',\n",
       " 'this world, neither in the world to come.  12:33',\n",
       " ' 18:7 woe unto the world because of offences! for',\n",
       " 'be preached in all the world for a witness unto',\n",
       " 'since the beginning of the world to this time, no,',\n",
       " 'with persecutions; and in the world to come eternal life.',\n",
       " 'which have been since the world began: 1:71 that we',\n",
       " 'caesar augustus that all the world should be taxed. ',\n",
       " 'all the kingdoms of the world in a moment of',\n",
       " 'do the nations of the world seek after: and your',\n",
       " 'for the children of this world are in their generation',\n",
       " 'present time, and in the world to come life everlasting.',\n",
       " 'them, the children of this world marry, and are given',\n",
       " 'in the world, and the world was made by him,',\n",
       " 'made by him, and the world knew him not. ',\n",
       " 'not his son into the world to condemn the world;',\n",
       " 'the world; but that the world through him might be',\n",
       " 'alway ready.  7:7 the world cannot hate you; but',\n",
       " 'and i speak to the world those things which i',\n",
       " 'heareth.  9:32 since the world began was it not',\n",
       " 'ye prevail nothing? behold, the world is gone after him.',\n",
       " 'hateth his life in this world shall keep it unto',\n",
       " 'shall the prince of this world be cast out. ',\n",
       " 'should depart out of this world unto the father, having',\n",
       " 'spirit of truth; whom the world cannot receive, because it',\n",
       " 'a little while, and the world seeth me no more;',\n",
       " 'unto you: not as the world giveth, give i unto',\n",
       " 'for the prince of this world cometh, and hath nothing',\n",
       " ' 14:31 but that the world may know that i',\n",
       " 'another.  15:18 if the world hate you, ye know',\n",
       " 'were of the world, the world would love his own:',\n",
       " 'of the world, therefore the world hateth you.  15:20',\n",
       " 'come, he will reprove the world of sin, and of',\n",
       " 'because the prince of this world is judged.  16:12',\n",
       " 'weep and lament, but the world shall rejoice: and ye',\n",
       " 'have peace.  in the world ye shall have tribulation:',\n",
       " 'had with thee before the world was.  17:6 i',\n",
       " 'them thy word; and the world hath hated them, because',\n",
       " 'one in us: that the world may believe that thou',\n",
       " 'in one; and that the world may know that thou',\n",
       " '17:25 o righteous father, the world hath not known thee:',\n",
       " 'i suppose that even the world itself could not contain',\n",
       " 'his holy prophets since the world began.  3:22 for',\n",
       " 'these that have turned the world upside down are come',\n",
       " '17:24 god that made the world and all things therein,',\n",
       " 'which he will judge the world in righteousness by that',\n",
       " 'whom all asia and the world worshippeth.  19:28 and',\n",
       " 'from the creation of the world are clearly seen, being',\n",
       " 'be stopped, and all the world may become guilty before',\n",
       " 'was kept secret since the world began, 16:26 but now',\n",
       " 'the wisdom of god the world by wisdom knew not',\n",
       " 'the foolish things of the world to confound the wise;',\n",
       " 'the weak things of the world to confound the things',\n",
       " 'which god ordained before the world unto our glory: 2:8',\n",
       " 'of the princes of this world knew: for had they',\n",
       " 'for the wisdom of this world is foolishness with god.',\n",
       " 'the world? and if the world shall be judged by',\n",
       " 'for the fashion of this world passeth away.  7:32',\n",
       " 'eat no flesh while the world standeth, lest i make',\n",
       " 'whom the ends of the world are come.  10:12',\n",
       " 'whom the god of this world hath blinded the minds',\n",
       " 'was in christ, reconciling the world unto himself, not imputing',\n",
       " 'but the sorrow of the world worketh death.  7:11',\n",
       " 'jesus christ, by whom the world is crucified unto me,',\n",
       " 'from the beginning of the world hath been hid in',\n",
       " 'christ jesus throughout all ages, world without end. amen. ',\n",
       " 'christ jesus came into the world to save sinners; of',\n",
       " 'in christ jesus before the world began, 1:10 but is',\n",
       " 'cannot lie, promised before the world began; 1:3 but hath',\n",
       " 'not put in subjection the world to come, whereof we',\n",
       " 'and the powers of the world to come, 6:6 if',\n",
       " 'in the end of the world hath he appeared to',\n",
       " 'tormented; 11:38 (of whom the world was not worthy:) they',\n",
       " 'chosen the poor of this world rich in faith, and',\n",
       " 'tongue is a fire, a world of iniquity: so is',\n",
       " 'that the friendship of the world is enmity with god?',\n",
       " 'be a friend of the world is the enemy of',\n",
       " 'corruption that is in the world through lust.  1:5',\n",
       " 'in the flood upon the world of the ungodly; 2:6',\n",
       " 'escaped the pollutions of the world through the knowledge of',\n",
       " 'the water: 3:6 whereby the world that then was, being',\n",
       " 'world.  2:17 and the world passeth away, and the',\n",
       " 'sons of god: therefore the world knoweth us not, because',\n",
       " 'not, my brethren, if the world hate you.  3:14',\n",
       " 'of the world, and the world heareth them.  4:6',\n",
       " 'of god, and the whole world lieth in wickedness. ',\n",
       " 'saying, the kingdoms of this world are become the kingdoms',\n",
       " 'was healed: and all the world wondered after the beast.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at what the algorithm has found\n",
    "concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how many instances of just the word \"world\" were found\n",
    "len(concordance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in the cell below, modify the code to search for a different word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add your modified code here and run the cell...\n",
    "concordance = []\n",
    "for i, val in enumerate(bible):\n",
    "    if val == \"kingdom\":\n",
    "        concordance.append(str(' '.join(bible[i-5:i+5])))\n",
    "\n",
    "len(concordance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nltk package has the full text of several other classic books. You can see what they are called by running the command in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn!\n",
    "\n",
    "Here are a some more things you can try. In each case, I have given you a little bit of starter code to get you going, but the cells will not run without some additional code from you.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Challenge 1: build your own concordance\n",
    "\n",
    "Pick a different book and a different word, or pair of words. Copy and paste from the code above to write some Python code that searches the book of your choice for the word or pair of words of your choice. Put this code in the cell below. By the way, some of the texts use the characters \"\\r\" for \"carriage return\" instead of \"\\n\" for \"newline\". You can remove these the same way that you remove the \"\\n\" characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "\n",
    "# create a variable called \"bible\" which contains the text of the King James bible.\n",
    "macbeth = nltk.corpus.gutenberg.raw('shakespeare-macbeth.txt')\n",
    "\n",
    "# make all characters lowercase\n",
    "macbeth = macbeth.lower()\n",
    "\n",
    "# remove the \"\\n\" characters, which indicate line breaks in the text (newlines)\n",
    "macbeth = macbeth.replace('\\n', ' ')\n",
    "\n",
    "# remove the \"\\r\" characters, which indicates carraige return\n",
    "macbeth = macbeth.replace('\\r', ' ')\n",
    "\n",
    "# split up the text into a long list of individual words\n",
    "macbeth = macbeth.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see instances of the word \"ye\"\n",
    "concordance = []\n",
    "for i, val in enumerate(macbeth):\n",
    "    if val == \"ye\":\n",
    "        concordance.append(str(' '.join(macbeth[i-5:i+5])))\n",
    "\n",
    "# see number of occurances\n",
    "len(concordance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"i'th' name of truth are ye fantasticall, or that indeed\",\n",
       " 'or that indeed which outwardly ye shew? my noble partner',\n",
       " 'macb. i, in the catalogue ye goe for men, as']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see concordance\n",
    "concordance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2: compare lengths of books\n",
    "\n",
    "We can use the command `len` to find how many items there are in a list. E.g., to find the number of words in the list called `bible`, above, we can write: `len(bible)`. \n",
    "\n",
    "Use the starter code below to find out which book in the books included in `nltk` has the most words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "austen-emma.txt: 164457 words\n",
      "austen-persuasion.txt: 86270 words\n",
      "austen-sense.txt: 123514 words\n",
      "burgess-busterbrown.txt: 17976 words\n",
      "bryant-stories.txt: 54942 words\n",
      "blake-poems.txt: 8886 words\n",
      "bible-kjv.txt: 848001 words\n",
      "milton-paradise.txt: 91832 words\n",
      "chesterton-ball.txt: 86481 words\n",
      "chesterton-brown.txt: 80382 words\n",
      "chesterton-thursday.txt: 59297 words\n",
      "shakespeare-caesar.txt: 23339 words\n",
      "shakespeare-hamlet.txt: 33477 words\n",
      "shakespeare-macbeth.txt: 20164 words\n",
      "whitman-leaves.txt: 138730 words\n",
      "melville-moby_dick.txt: 243947 words\n",
      "edgeworth-parents.txt: 195982 words\n",
      "carroll-alice.txt: 28387 words\n",
      "\n",
      "'bible-kjv.txt' has 848001 words.\n"
     ]
    }
   ],
   "source": [
    "# solution 1: print all the titles and numbers of words\n",
    "# starter code:\n",
    "\n",
    "# get list of books\n",
    "books = nltk.corpus.gutenberg.fileids()\n",
    "\n",
    "# initialize variables to store the book with the most words\n",
    "max_words = 0\n",
    "longest_book = \"\"\n",
    "\n",
    "# loop through each book\n",
    "for title in books:\n",
    "    book = nltk.corpus.gutenberg.raw(title)\n",
    "\n",
    "    # make all characters lowercase\n",
    "    book = book.lower()\n",
    "    \n",
    "    # remove the \"\\n\" characters, which indicate line breaks in the text (newlines)\n",
    "    book = book.replace('\\n', ' ')\n",
    "\n",
    "    # remove the \"\\r\" characters, which indicate carriage return\n",
    "    book = book.replace('\\r', ' ')\n",
    "\n",
    "    # split up the text into a long list of individual words\n",
    "    book = book.split(' ')\n",
    "    \n",
    "    # count number of words\n",
    "    num_words = len(book)\n",
    "    \n",
    "    # print book title and the number of words\n",
    "    print(f\"{title}: {num_words} words\")\n",
    "    \n",
    "    # check for each book if it has the most words\n",
    "    if num_words > max_words:\n",
    "        max_words = num_words\n",
    "        longest_book = title\n",
    "\n",
    "# print book with the highest number of words\n",
    "print(f\"\\n'{longest_book}' has {max_words} words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more advanced, for those with some Python experience, or those who want to google around..\n",
    "# solution 2: make a list of titles and a list of wordcounts, zip them together, then sort them based on wordcount\n",
    "# starter code:\n",
    "\n",
    "#books = nltk.corpus.gutenberg.fileids()\n",
    "\n",
    "#titles = []\n",
    "#numwords = []\n",
    "#for title in books:\n",
    "#    book = nltk.corpus.gutenberg.raw(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3: what are the most frequent words?\n",
    "\n",
    "`nltk` has a built-in function called `FreqDist` which counts up how many times each word in a text occurs. So, if you have a list called `words` which contains all the words in a book, you can find the frequencies of all of them by writing `freq = nltk.FreqDist(words)`. You can then get the e.g. ten most common words by writing `freq.most_common(10)`. What are the ten most common words in Jane Austen's \"Emma\"? What about Herman Melville's \"Moby Dick\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 6290),\n",
       " ('the', 5120),\n",
       " ('to', 5079),\n",
       " ('and', 4445),\n",
       " ('of', 4196),\n",
       " ('a', 3055),\n",
       " ('i', 2602),\n",
       " ('was', 2302),\n",
       " ('she', 2169),\n",
       " ('in', 2091)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JANE AUSTEN - EMMA\n",
    "\n",
    "# starter code:\n",
    "book = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
    "words = book.lower()\n",
    "\n",
    "# remove the \"\\n\" characters, which indicate line breaks in the text (newlines)\n",
    "words = words.replace('\\n', ' ')\n",
    "\n",
    "# remove the \"\\r\" characters, which indicate carriage return\n",
    "words = words.replace('\\r', ' ')\n",
    "\n",
    "# split up the text into a long list of individual words\n",
    "words = words.split(' ')\n",
    "\n",
    "# get frequency of all words\n",
    "freq = nltk.FreqDist(words)\n",
    "\n",
    "# get the frequency of the 10 most common words\n",
    "freq.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 31917),\n",
       " ('the', 14226),\n",
       " ('of', 6545),\n",
       " ('and', 6238),\n",
       " ('a', 4597),\n",
       " ('to', 4518),\n",
       " ('in', 4058),\n",
       " ('that', 2744),\n",
       " ('his', 2485),\n",
       " ('it', 1765)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HERMAN MELVILLE - MOBY DICK\n",
    "\n",
    "# starter code:\n",
    "book = nltk.corpus.gutenberg.raw('melville-moby_dick.txt')\n",
    "words = book.lower()\n",
    "\n",
    "# remove the \"\\n\" characters, which indicate line breaks in the text (newlines)\n",
    "words = words.replace('\\n', ' ')\n",
    "\n",
    "# remove the \"\\r\" characters, which indicate carriage return\n",
    "words = words.replace('\\r', ' ')\n",
    "\n",
    "# split up the text into a long list of individual words\n",
    "words = words.split(' ')\n",
    "\n",
    "# get frequency of all words\n",
    "freq = nltk.FreqDist(words)\n",
    "\n",
    "# get the frequency of the 10 most common words\n",
    "freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 2041),\n",
       " ('the', 439),\n",
       " ('and', 340),\n",
       " ('of', 146),\n",
       " ('in', 140),\n",
       " ('a', 126),\n",
       " ('i', 122),\n",
       " ('to', 111),\n",
       " ('my', 83),\n",
       " ('with', 66)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WILLIAM BLAKE - POEMS\n",
    "# starter code:\n",
    "book = nltk.corpus.gutenberg.raw('blake-poems.txt')\n",
    "words = book.lower()\n",
    "\n",
    "# remove the \"\\n\" characters, which indicate line breaks in the text (newlines)\n",
    "words = words.replace('\\n', ' ')\n",
    "\n",
    "# remove the \"\\r\" characters, which indicate carriage return\n",
    "words = words.replace('\\r', ' ')\n",
    "\n",
    "# split up the text into a long list of individual words\n",
    "words = words.split(' ')\n",
    "\n",
    "# get frequency of all words\n",
    "freq = nltk.FreqDist(words)\n",
    "\n",
    "# get the frequency of the 10 most common words\n",
    "freq.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 4: Remove stopwords\n",
    "\n",
    "Often, the most frequent words are not the most interesting ones. Words like \"a\" and \"the\" are so common in English, that they don't really tell us much about the text. That is why we often remove \"stopwords\", that is, a list of the most common words in English, before e.g. counting frequencies. There are several of these lists available, in [English]((https://gist.github.com/sebleier/554280)) as well as other languages, such as [Danish](https://gist.github.com/berteltorp/0cf8a0c7afea7f25ed754f24cfc2467b). Below is some starter code to remove stopwords. Use these snippets to see what the most common words in Emma and Moby Dick are after removing these most common words.\n",
    "\n",
    "Hint: In Moby Dick, you will also have to remove the string `\\r`, in addition to removing `\\n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of stopwords\n",
    "\n",
    "stopwords = [\"\", \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of stopwords\n",
    "\n",
    "stopwords = [\"\", \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mr.', 1097),\n",
       " ('could', 800),\n",
       " ('would', 795),\n",
       " ('mrs.', 675),\n",
       " ('miss', 568),\n",
       " ('must', 543),\n",
       " ('emma', 481),\n",
       " ('much', 427),\n",
       " ('every', 425),\n",
       " ('said', 392)]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JANE AUSTEN - EMMA\n",
    "\n",
    "# starter code:\n",
    "book = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
    "words = book.lower()\n",
    "\n",
    "# remove the \"\\n\" characters, which indicate line breaks in the text (newlines)\n",
    "words = words.replace('\\n', ' ')\n",
    "\n",
    "# remove the \"\\r\" characters, which indicate carriage return\n",
    "words = words.replace('\\r', ' ')\n",
    "\n",
    "# split up the text into a long list of individual words\n",
    "words = words.split(' ')\n",
    "\n",
    "# code to remove stopwords\n",
    "words = [word for word in words if word not in stopwords]\n",
    "\n",
    "# get frequency of all words\n",
    "freq = nltk.FreqDist(words)\n",
    "\n",
    "# get the frequency of the 10 most common words\n",
    "freq.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('one', 779),\n",
       " ('like', 564),\n",
       " ('upon', 556),\n",
       " ('whale', 528),\n",
       " ('old', 425),\n",
       " ('would', 416),\n",
       " ('though', 311),\n",
       " ('great', 292),\n",
       " ('still', 282),\n",
       " ('seemed', 273)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HERMAN MELVILLE - MOBY DICK\n",
    "\n",
    "# starter code:\n",
    "book = nltk.corpus.gutenberg.raw('melville-moby_dick.txt')\n",
    "words = book.lower()\n",
    "\n",
    "# remove the \"\\n\" characters, which indicate line breaks in the text (newlines)\n",
    "words = words.replace('\\n', ' ')\n",
    "\n",
    "# remove the \"\\r\" characters, which indicate carriage return\n",
    "words = words.replace('\\r', ' ')\n",
    "\n",
    "# split up the text into a long list of individual words\n",
    "words = words.split(' ')\n",
    "\n",
    "# code to remove stopwords\n",
    "words = [word for word in words if word not in stopwords]\n",
    "\n",
    "# get frequency of all words\n",
    "freq = nltk.FreqDist(words)\n",
    "\n",
    "# get the frequency of the 10 most common words\n",
    "freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('little', 45),\n",
       " ('like', 35),\n",
       " ('thou', 33),\n",
       " ('thy', 31),\n",
       " ('sweet', 26),\n",
       " ('thee', 19),\n",
       " ('shall', 19),\n",
       " ('happy', 18),\n",
       " ('every', 17),\n",
       " ('&', 17)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WILLIAM BLAKE - POEMS\n",
    "\n",
    "# starter code:\n",
    "book = nltk.corpus.gutenberg.raw('blake-poems.txt')\n",
    "words = book.lower()\n",
    "\n",
    "# remove the \"\\n\" characters, which indicate line breaks in the text (newlines)\n",
    "words = words.replace('\\n', ' ')\n",
    "\n",
    "# remove the \"\\r\" characters, which indicate carriage return\n",
    "words = words.replace('\\r', ' ')\n",
    "\n",
    "# split up the text into a long list of individual words\n",
    "words = words.split(' ')\n",
    "\n",
    "# code to remove stopwords\n",
    "words = [word for word in words if word not in stopwords]\n",
    "\n",
    "# get frequency of all words\n",
    "freq = nltk.FreqDist(words)\n",
    "\n",
    "# get the frequency of the 10 most common words\n",
    "freq.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done finito :P"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
